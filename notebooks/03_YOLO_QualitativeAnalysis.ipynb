{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe5813ab",
   "metadata": {},
   "source": [
    "#### Qualitative Analysis\n",
    "\n",
    "1. By python script - run `src.autonomous_vision.object_detection.yolo_overlay` (Refer readme for how to run it) - This script will save images with GT bounding boxes and predicted bounding boxes overlaid on them.\n",
    "\n",
    "2. This can also be done using FiftyOne app.Follow this notebook for details and analysis \n",
    "\n",
    "3. Analysis given at bottom of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "501ad59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "from ultralytics import YOLO\n",
    "import fiftyone.utils.yolo as fouy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d77528",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"bdd100k-val-ultralytics-pred\"\n",
    "\n",
    "if fo.dataset_exists(DATASET_NAME):\n",
    "    fo.delete_dataset(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1681f044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████| 10000/10000 [1.1m elapsed, 0s remaining, 146.2 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "name = \"bdd100k-val-ultralytics-pred\"\n",
    "dataset_dir = \"../data/yolo_data\"\n",
    "\n",
    "# Create the dataset\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=dataset_dir,\n",
    "    dataset_type=fo.types.YOLOv5Dataset, \n",
    "    name=name,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ddaf102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████| 10000/10000 [3.6m elapsed, 0s remaining, 50.7 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"../models/yolo11s_bdd.pt\")\n",
    "dataset.apply_model(model, label_field=\"YOLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c181801c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=c0ce57d7-5b7e-4370-a0da-26f5aaa6a73e\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa76a2cca70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset:     -\n",
       "Session URL: http://localhost:5151/"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fo.launch_app(auto=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340f5923",
   "metadata": {},
   "source": [
    "The qualitative analysis reveals that the model performs strongly for large, frequent classes like cars, with bounding boxes closely aligned to ground truth (IoU > 0.8), even under moderate occlusion or challenging lighting such as tunnels and rainy conditions as predicted by quantitative analysis. \n",
    "\n",
    "However, small and less frequent objects like traffic lights, traffic signs, and bikes show poorer localization accuracy, with bounding boxes often shifted from ground truth (IoU dropping to 0.5–0.7) or entirely missed in low-light \n",
    "\n",
    "False positives appear in rare contexts such as tunnels and heavy rain, due to weak generalization. These observations align with earlier data analysis - strong performance is linked to dominant classes with ample representation, while weaker detection corresponds to dataset imbalance in class frequency, object size, and environmental diversity. \n",
    "\n",
    " Need to do targeted augmentation to improve IoU and recall for small and rare classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
